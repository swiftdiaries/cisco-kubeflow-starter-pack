{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Traffic Dataset for malicious attack\n",
    "\n",
    "This dataset of network traffic flow is generated by CICFlowMeter, indicate whether the traffic is malicious attack (Bot) or not (Benign).                             \n",
    "CICFlowMeter - network traffic flow generator generates 69 statistical features such as Duration, Number of packets, Number of bytes, Length of packets, etc are also calculated separately in the forward and reverse direction.   \n",
    "The output of the application is the CSV file format with two columns labeled for each flow, namely Benign or Bot.\n",
    "The dataset has been organized per day, for each day the raw data including the network traffic (Pcaps) and event logs (windows and Ubuntu event Logs) per machine\n",
    "are recorded.                  Download the dataset from the below wget command line provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://cse-cic-ids2018.s3.ca-central-1.amazonaws.com/Processed+Traffic+Data+for+ML+Algorithms/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas --user\n",
    "! pip install imblearn --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart Notebook Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstZerodrp = ['Timestamp', 'BwdPSHFlags', 'FwdURGFlags', 'BwdURGFlags', 'CWEFlagCount', 'FwdBytsbAvg', 'FwdPktsbAvg',\n",
    "              'FwdBlkRateAvg', 'BwdBytsbAvg',\n",
    "              'BwdBlkRateAvg', 'BwdPktsbAvg']\n",
    "\n",
    "lstScaledrp = ['FwdPSHFlags', 'FINFlagCnt', 'SYNFlagCnt', 'RSTFlagCnt', 'PSHFlagCnt', 'ACKFlagCnt', 'URGFlagCnt',\n",
    "               'ECEFlagCnt']\n",
    "\n",
    "DATA_FILE = 'Network_Traffic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataFile():\n",
    "    \"\"\"\n",
    "    Reads data file and returns dataframe result\n",
    "    \"\"\"\n",
    "    chunksize = 100000\n",
    "    chunk_list = []\n",
    "    missing_values = [\"n/a\", \"na\", \"--\", \"Infinity\", \"infinity\", \"Nan\", \"NaN\"]\n",
    "\n",
    "    for chunk in pd.read_csv(DATA_FILE, chunksize=chunksize, na_values=missing_values):\n",
    "        chunk_list.append(chunk)\n",
    "#         break\n",
    "    dataFrme = pd.concat(chunk_list)\n",
    "\n",
    "    lstcols = []\n",
    "    for i in dataFrme.columns:\n",
    "        i = str(i).replace(' ', '').replace('/', '')\n",
    "        lstcols.append(i)\n",
    "    dataFrme.columns = lstcols\n",
    "    dfAllCpy = dataFrme.copy()\n",
    "    dataFrme = dataFrme.drop(lstZerodrp, axis=1)\n",
    "    return dataFrme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Traffic Input Dataset \n",
    "\n",
    "### Attribute Information\n",
    "    Features extracted from the captured traffic using CICFlowMeter-V3 = 69\n",
    "    After removal of noise/unwarranted features, number of feature columns chosen: 10\n",
    "    Features: FlowDuration,BwdPktLenMax,FlowIATStd,FwdPSHFlags,BwdPktLenMean,FlowIATMean,BwdIATMean,\n",
    "              FwdSegSizeMin,InitBwdWinByts,BwdPktLenMin\n",
    "    Flows labelled: Bot or Benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DstPort</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>FlowDuration</th>\n",
       "      <th>TotFwdPkts</th>\n",
       "      <th>TotBwdPkts</th>\n",
       "      <th>TotLenFwdPkts</th>\n",
       "      <th>TotLenBwdPkts</th>\n",
       "      <th>FwdPktLenMax</th>\n",
       "      <th>FwdPktLenMin</th>\n",
       "      <th>FwdPktLenMean</th>\n",
       "      <th>...</th>\n",
       "      <th>FwdSegSizeMin</th>\n",
       "      <th>ActiveMean</th>\n",
       "      <th>ActiveStd</th>\n",
       "      <th>ActiveMax</th>\n",
       "      <th>ActiveMin</th>\n",
       "      <th>IdleMean</th>\n",
       "      <th>IdleStd</th>\n",
       "      <th>IdleMax</th>\n",
       "      <th>IdleMin</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>141385</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>553</td>\n",
       "      <td>3773.0</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>61.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49684</td>\n",
       "      <td>6</td>\n",
       "      <td>281</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>279824</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>1086</td>\n",
       "      <td>10527.0</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>98.727273</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>274016</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>1285</td>\n",
       "      <td>6141.0</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "      <td>142.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DstPort  Protocol  FlowDuration  TotFwdPkts  TotBwdPkts  TotLenFwdPkts  \\\n",
       "0      443         6        141385           9           7            553   \n",
       "1    49684         6           281           2           1             38   \n",
       "2      443         6        279824          11          15           1086   \n",
       "3      443         6           132           2           0              0   \n",
       "4      443         6        274016           9          13           1285   \n",
       "\n",
       "   TotLenBwdPkts  FwdPktLenMax  FwdPktLenMin  FwdPktLenMean  ...  \\\n",
       "0         3773.0           202             0      61.444444  ...   \n",
       "1            0.0            38             0      19.000000  ...   \n",
       "2        10527.0           385             0      98.727273  ...   \n",
       "3            0.0             0             0       0.000000  ...   \n",
       "4         6141.0           517             0     142.777778  ...   \n",
       "\n",
       "   FwdSegSizeMin  ActiveMean  ActiveStd  ActiveMax  ActiveMin  IdleMean  \\\n",
       "0             20         0.0        0.0        0.0        0.0       0.0   \n",
       "1             20         0.0        0.0        0.0        0.0       0.0   \n",
       "2             20         0.0        0.0        0.0        0.0       0.0   \n",
       "3             20         0.0        0.0        0.0        0.0       0.0   \n",
       "4             20         0.0        0.0        0.0        0.0       0.0   \n",
       "\n",
       "   IdleStd  IdleMax  IdleMin   Label  \n",
       "0      0.0      0.0      0.0  Benign  \n",
       "1      0.0      0.0      0.0  Benign  \n",
       "2      0.0      0.0      0.0  Benign  \n",
       "3      0.0      0.0      0.0  Benign  \n",
       "4      0.0      0.0      0.0  Benign  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dataFile().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_na(dataFrme):\n",
    "    \"\"\"\n",
    "    Removing NA values\n",
    "    \"\"\"\n",
    "    na_lst = dataFrme.columns[dataFrme.isna().any()].tolist()\n",
    "    for j in na_lst:\n",
    "        dataFrme[j].fillna(0, inplace=True)\n",
    "    return dataFrme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_label(dataFrme):\n",
    "    \"\"\"\n",
    "    Create independent and Dependent Features\n",
    "    \"\"\"\n",
    "    columns = dataFrme.columns.tolist()\n",
    "    # Filter the columns to remove data we do not want \n",
    "    columns = [c for c in columns if c not in [\"Label\"]]\n",
    "    # Store the variable we are predicting \n",
    "    target = \"Label\"\n",
    "    # Define a random state \n",
    "    state = np.random.RandomState(42)\n",
    "    X = dataFrme[columns]\n",
    "    Y = dataFrme[target]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_substitution(dataFrme):\n",
    "    \"\"\"\n",
    "    Label substitution : 'Benign'as 0, 'Bot'as 1\n",
    "    \"\"\"\n",
    "    dictLabel = {'Benign': 0, 'Bot': 1}\n",
    "    dataFrme['Label'] = dataFrme['Label'].map(dictLabel)\n",
    "\n",
    "    LABELS = ['Benign', 'Bot']\n",
    "    count_classes = pd.value_counts(dataFrme['Label'], sort=True)\n",
    "    \n",
    "    # Get the Benign and the Bot values \n",
    "    Benign = dataFrme[dataFrme['Label'] == 0]\n",
    "    Bot = dataFrme[dataFrme['Label'] == 1]\n",
    "    return dataFrme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_class_imbalance(X,Y):\n",
    "    \"\"\"\n",
    "    Handle Class imbalancement \n",
    "    \"\"\"\n",
    "#    os_us = SMOTETomek(ratio=0.5)\n",
    "#    X_res, y_res = os_us.fit_sample(X, Y)\n",
    "    ros = RandomOverSampler(random_state=50)\n",
    "    X_res, y_res = ros.fit_sample(X, Y)\n",
    "    ibtrain_X = pd.DataFrame(X_res,columns=X.columns)\n",
    "    ibtrain_y = pd.DataFrame(y_res,columns=['Label']) \n",
    "    return ibtrain_X,ibtrain_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_features(ibtrain_X):\n",
    "    \"\"\"\n",
    "    Feature Selection - Correlation Ananlysis \n",
    "    \"\"\"\n",
    "    corr = ibtrain_X.corr()\n",
    "    cor_columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "    for i in range(corr.shape[0]):\n",
    "        for j in range(i + 1, corr.shape[0]):\n",
    "            if corr.iloc[i, j] >= 0.9:\n",
    "                if cor_columns[j]:\n",
    "                    cor_columns[j] = False\n",
    "\n",
    "    dfcorr_features = ibtrain_X[corr.columns[cor_columns]]\n",
    "    return dfcorr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_ten_features(dfcorr_features,ibtrain_X,ibtrain_y):\n",
    "    feat_X = dfcorr_features\n",
    "    feat_y = ibtrain_y['Label']\n",
    "    \n",
    "    #apply SelectKBest class to extract top 10 best features\n",
    "    bestfeatures = SelectKBest(score_func=f_classif, k=10)\n",
    "    fit = bestfeatures.fit(feat_X,feat_y)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(feat_X.columns)\n",
    "    #concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Features','Score']  #naming the dataframe columns\n",
    "    final_feature = featureScores.nlargest(10,'Score')['Features'].tolist()\n",
    "    final_feature.sort()\n",
    "    sort_fn = final_feature\n",
    "    dictLabel1 = {'Benign':0,'Bot':1}\n",
    "    ibtrain_y['Label']= ibtrain_y['Label'].map(dictLabel1)\n",
    "    selected_X = ibtrain_X[sort_fn]\n",
    "    selected_Y = ibtrain_y['Label']\n",
    "    return selected_X,selected_Y,sort_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(selected_X, selected_Y):\n",
    "    \"\"\"\n",
    "    Normalize data \n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    selected_X = pd.DataFrame(scaler.fit_transform(selected_X), columns=selected_X.columns, index=selected_X.index)\n",
    "    trainX, testX, trainY, testY = train_test_split(selected_X, selected_Y, test_size=0.25)\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(\"## Final features and Data pre-process for prediction\")\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(testX)\n",
    "    return trainX, testX, trainY, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "## Final features and Data pre-process for prediction\n",
      "-----------------------------------------------------------------\n",
      "         BwdPktLenMax  BwdPktLenMean  BwdPktLenMin  FlowDuration  \\\n",
      "381275       0.334247       0.083583      0.000000  7.316667e-06   \n",
      "1492714      0.000000       0.000000      0.000000  3.800000e-06   \n",
      "63195        0.076712       0.022095      0.000000  8.380834e-05   \n",
      "1442888      0.000000       0.000000      0.000000  4.425000e-06   \n",
      "1085854      0.000000       0.000000      0.000000  3.733333e-06   \n",
      "...               ...            ...           ...           ...   \n",
      "434362       0.041096       0.041107      0.041958  4.731250e-04   \n",
      "576733       0.000000       0.000000      0.000000  2.666667e-07   \n",
      "1129082      0.076712       0.022095      0.000000  8.494167e-05   \n",
      "191419       0.076712       0.022095      0.000000  8.836667e-05   \n",
      "1169953      0.076712       0.022095      0.000000  9.154167e-05   \n",
      "\n",
      "           FlowIATMax  FwdPktLenMin  FwdSegSizeMin  InitBwdWinByts  Protocol  \\\n",
      "381275   2.425000e-06      0.000000       0.454545        0.002289  0.352941   \n",
      "1492714  3.800000e-06      0.000000       0.454545        0.000000  0.352941   \n",
      "63195    7.681667e-05      0.000000       0.454545        0.003357  0.352941   \n",
      "1442888  4.425000e-06      0.000000       0.454545        0.000000  0.352941   \n",
      "1085854  3.733333e-06      0.000000       0.454545        0.000000  0.352941   \n",
      "...               ...           ...            ...             ...       ...   \n",
      "434362   4.645500e-04      0.030137       0.181818        0.000000  1.000000   \n",
      "576733   2.666667e-07      0.000000       0.454545        0.000000  0.352941   \n",
      "1129082  7.680000e-05      0.000000       0.454545        0.003357  0.352941   \n",
      "191419   7.839167e-05      0.000000       0.454545        0.003357  0.352941   \n",
      "1169953  8.327500e-05      0.000000       0.454545        0.003357  0.352941   \n",
      "\n",
      "         RSTFlagCnt  \n",
      "381275          0.0  \n",
      "1492714         0.0  \n",
      "63195           1.0  \n",
      "1442888         0.0  \n",
      "1085854         0.0  \n",
      "...             ...  \n",
      "434362          0.0  \n",
      "576733          0.0  \n",
      "1129082         1.0  \n",
      "191419          1.0  \n",
      "1169953         1.0  \n",
      "\n",
      "[381192 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "'''Reads data file and returns dataframe result'''\n",
    "dataFrme = read_dataFile()\n",
    "\n",
    "''' Removing NA values'''\n",
    "dataFrme = preprocess_na(dataFrme)\n",
    "\n",
    "'''Create independent and Dependent Features'''\n",
    "X, Y = create_features_label(dataFrme)\n",
    "\n",
    "'''Label substitution : 'Benign'as 0, 'Bot'as 1'''\n",
    "dataFrme = label_substitution(dataFrme)\n",
    "\n",
    "'''Handle Class imbalancement'''\n",
    "ibtrain_X, ibtrain_y = handle_class_imbalance(X, Y)\n",
    "\n",
    "'''Feature Selection - Correlation Ananlysis'''\n",
    "dfcorr_features = correlation_features(ibtrain_X)\n",
    "\n",
    "'''Feature Selection - SelectKBest : Return best 10 features'''\n",
    "selected_X, selected_Y, final_feature = top_ten_features(dfcorr_features, ibtrain_X, ibtrain_y)\n",
    "\n",
    "'''Normalize data '''\n",
    "trainX, testX, trainY, testY = normalize_data(selected_X, selected_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Serving Input Receiver Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_cols():\n",
    "  input_columns = [tf.feature_column.numeric_column(k,dtype=tf.dtypes.float64) for k in final_feature]\n",
    "  return input_columns\n",
    "feature_columns =  make_feature_cols()\n",
    "inputs = {}\n",
    "for feat in feature_columns:\n",
    "  inputs[feat.name] = tf.placeholder(shape=[None], dtype=feat.dtype)\n",
    "serving_input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Save Network Traffic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_DATA_DIR = os.getenv(\"TF_DATA_DIR\", \"/tmp/data/\")\n",
    "TF_MODEL_DIR = os.getenv(\"TF_MODEL_DIR\", \"network/\")\n",
    "TF_EXPORT_DIR = os.getenv(\"TF_EXPORT_DIR\", \"network/\")\n",
    "\n",
    "x1 = np.asarray(trainX[final_feature])\n",
    "y1 = np.asarray(trainY)\n",
    "\n",
    "x2 = np.asarray(testX[final_feature])\n",
    "y2 = np.asarray(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatFeatures(features):\n",
    "    formattedFeatures = {}\n",
    "    numColumns = features.shape[1]\n",
    "\n",
    "    for i in range(0, numColumns):\n",
    "        formattedFeatures[final_feature[i]] = features[:, i]\n",
    "\n",
    "    return formattedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'network/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3364315e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/model_fn.py:337: scalar (from tensorflow.python.framework.tensor_shape) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.TensorShape([]).\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into network/model.ckpt.\n",
      "INFO:tensorflow:loss = 22.350811, step = 0\n",
      "INFO:tensorflow:global_step/sec: 204.696\n",
      "INFO:tensorflow:loss = 9.264154, step = 100 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.66\n",
      "INFO:tensorflow:loss = 3.3205647, step = 200 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.999\n",
      "INFO:tensorflow:loss = 6.1276293, step = 300 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.911\n",
      "INFO:tensorflow:loss = 7.227752, step = 400 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.756\n",
      "INFO:tensorflow:loss = 7.7608004, step = 500 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.044\n",
      "INFO:tensorflow:loss = 7.0279064, step = 600 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.701\n",
      "INFO:tensorflow:loss = 7.1396246, step = 700 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.93\n",
      "INFO:tensorflow:loss = 7.17324, step = 800 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.114\n",
      "INFO:tensorflow:loss = 4.5179095, step = 900 (0.420 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into network/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-22T13:08:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from network/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-22-13:08:44\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.918125, accuracy_baseline = 0.5015625, auc = 0.9705006, auc_precision_recall = 0.97359693, average_loss = 0.18827882, global_step = 1000, label/mean = 0.5015625, loss = 6.0249224, precision = 0.8600536, prediction/mean = 0.48737636, recall = 0.99937695\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: network/model.ckpt-1000\n",
      "INFO:tensorflow:Performing the final export in the end of training.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'BwdPktLenMax': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float64>, 'BwdPktLenMean': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float64>, 'BwdPktLenMin': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float64>, 'FlowDuration': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float64>, 'FlowIATMax': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float64>, 'FwdPktLenMin': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=float64>, 'FwdSegSizeMin': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=float64>, 'InitBwdWinByts': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=float64>, 'Protocol': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=float64>, 'RSTFlagCnt': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=float64>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'BwdPktLenMax': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float64>, 'BwdPktLenMean': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float64>, 'BwdPktLenMin': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float64>, 'FlowDuration': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float64>, 'FlowIATMax': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float64>, 'FwdPktLenMin': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=float64>, 'FwdSegSizeMin': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=float64>, 'InitBwdWinByts': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=float64>, 'Protocol': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=float64>, 'RSTFlagCnt': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=float64>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'BwdPktLenMax': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float64>, 'BwdPktLenMean': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float64>, 'BwdPktLenMin': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float64>, 'FlowDuration': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float64>, 'FlowIATMax': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float64>, 'FwdPktLenMin': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=float64>, 'FwdSegSizeMin': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=float64>, 'InitBwdWinByts': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=float64>, 'Protocol': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=float64>, 'RSTFlagCnt': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=float64>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from network/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: network/export/network/temp-b'1587560925'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 6.4699574.\n",
      "({'accuracy': 0.918125, 'accuracy_baseline': 0.5015625, 'auc': 0.9705006, 'auc_precision_recall': 0.97359693, 'average_loss': 0.18827882, 'label/mean': 0.5015625, 'loss': 6.0249224, 'precision': 0.8600536, 'prediction/mean': 0.48737636, 'recall': 0.99937695, 'global_step': 1000}, [b'network/export/network/1587560925'])\n",
      "Training finished successfully\n"
     ]
    }
   ],
   "source": [
    "trainingFeatures = formatFeatures(x1)\n",
    "trainingCategories = y1\n",
    "\n",
    "testFeatures = formatFeatures(x2)\n",
    "testCategories = y2\n",
    "\n",
    "config = tf.estimator.RunConfig(model_dir=TF_MODEL_DIR, save_summary_steps=100, save_checkpoints_steps=1000)\n",
    "\n",
    "model = tf.estimator.DNNClassifier(hidden_units=[13,65,110],\n",
    "                                   feature_columns=feature_columns,\n",
    "                                   model_dir=TF_MODEL_DIR,\n",
    "                                   n_classes=2, config=config\n",
    "                                   )\n",
    "# Train Input Function\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((trainingFeatures, y1))\n",
    "    dataset = dataset.batch(32).repeat(1000)\n",
    "    return dataset\n",
    "\n",
    "# Test Input Function\n",
    "def eval_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((testFeatures, y2))\n",
    "    return dataset.batch(32).repeat(1000)\n",
    "\n",
    "export_final = tf.estimator.FinalExporter(TF_EXPORT_DIR, serving_input_receiver_fn=serving_input_receiver_fn)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn,\n",
    "                                    max_steps=1000)\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn,\n",
    "                                  steps=100,\n",
    "                                  exporters=export_final,\n",
    "                                  throttle_secs=1,\n",
    "                                  start_delay_secs=1)\n",
    "\n",
    "result = tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n",
    "print(result)\n",
    "\n",
    "print('Training finished successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update  storageUri in network_kfserving.yaml with pvc-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: \"serving.kubeflow.org/v1alpha2\"\r\n",
      "kind: \"InferenceService\"\r\n",
      "metadata:\r\n",
      "  name: \"network-model\"\r\n",
      "  namespace: anonymous\r\n",
      "spec:\r\n",
      "  default:\r\n",
      "    predictor:\r\n",
      "      tensorflow:\r\n",
      "        storageUri: \"pvc://workspace-gpu-test/network/export/network\"\r\n"
     ]
    }
   ],
   "source": [
    "pvcname = !(echo  $HOSTNAME | sed 's/.\\{2\\}$//')\n",
    "pvc = \"workspace-\"+pvcname[0]\n",
    "! sed -i \"s/nfs/$pvc/g\" network_kfserving.yaml\n",
    "! cat network_kfserving.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving Network Traffic Model using kubeflow kfserving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kubeflow.org/network-model created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f network_kfserving.yaml -n anonymous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME            URL                                                                  READY   DEFAULT TRAFFIC   CANARY TRAFFIC   AGE\r\n",
      "network-model   http://network-model.anonymous.example.com/v1/models/network-model   True    100                                69s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get inferenceservices -n anonymous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "Wait for inference service READY=\\\"True\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict data from serving after setting INGRESS_IP\n",
    "### Note - Use one of preprocessed row values from Data pre-process from prediction output cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying 10.30.118.172...\n",
      "* TCP_NODELAY set\n",
      "* Connected to 10.30.118.172 (10.30.118.172) port 31380 (#0)\n",
      "> POST /v1/models/network-model:predict HTTP/1.1\n",
      "> Host: network-model.anonymous.example.com\n",
      "> User-Agent: curl/7.58.0\n",
      "> Accept: */*\n",
      "> Content-Length: 301\n",
      "> Content-Type: application/x-www-form-urlencoded\n",
      "> \n",
      "* upload completely sent off: 301 out of 301 bytes\n",
      "< HTTP/1.1 200 OK\n",
      "< content-length: 305\n",
      "< content-type: application/json\n",
      "< date: Wed, 22 Apr 2020 13:12:05 GMT\n",
      "< x-envoy-upstream-service-time: 10434\n",
      "< server: istio-envoy\n",
      "< \n",
      "{\n",
      "    \"predictions\": [\n",
      "        {\n",
      "            \"all_class_ids\": [0, 1],\n",
      "            \"logistic\": [0.0],\n",
      "            \"all_classes\": [\"0\", \"1\"],\n",
      "            \"probabilities\": [1.0, 4.74031425e-10],\n",
      "            \"logits\": [-21.4697475],\n",
      "            \"class_ids\": [0],\n",
      "            \"classes\": [\"0\"]\n",
      "        }\n",
      "    ]\n",
      "* Connection #0 to host 10.30.118.172 left intact\n",
      "}"
     ]
    }
   ],
   "source": [
    "! curl -v -H \"Host: network-model.anonymous.example.com\" http://<<INGRESS_IP>>:<<PORT>>/v1/models/network-model:predict -d '{\"signature_name\":\"predict\",\"instances\":[{\"BwdPktLenMax\":[0.158904] , \"BwdPktLenMean\":[0.039736] , \"BwdPktLenMin\":[0.00000], \"FlowDuration\":[0.053778] , \"FlowIATMax\":[0.053262] , \"FwdPktLenMin\":[0.0] , \"FwdSegSizeMin\":[0.454545] , \"InitBwdWinByts\":[1.0] , \"Protocol\":[0.0] , \"RSTFlagCnt\":[0.003357]}]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete kfserving model & Clean up of stored models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kubeflow.org \"network-model\" deleted\n",
      "apiVersion: \"serving.kubeflow.org/v1alpha2\"\n",
      "kind: \"InferenceService\"\n",
      "metadata:\n",
      "  name: \"network-model\"\n",
      "  namespace: anonymous\n",
      "spec:\n",
      "  default:\n",
      "    predictor:\n",
      "      tensorflow:\n",
      "        storageUri: \"pvc://nfs/network/export/network\"\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f network_kfserving.yaml\n",
    "!rm -rf /mnt/network\n",
    "pvcname = !(echo  $HOSTNAME | sed 's/.\\{2\\}$//')\n",
    "pvc = \"workspace-\"+pvcname[0]\n",
    "! sed -i \"s/$pvc/nfs/g\" network_kfserving.yaml\n",
    "! cat network_kfserving.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
