{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Traffic Dataset for malicious attack\n",
    "\n",
    "This dataset of network traffic flow is generated by CICFlowMeter, indicate whether the traffic is malicious attack (Bot) or not (Benign).                             \n",
    "CICFlowMeter - network traffic flow generator generates 69 statistical features such as Duration, Number of packets, Number of bytes, Length of packets, etc are also calculated separately in the forward and reverse direction.   \n",
    "The output of the application is the CSV file format with two columns labeled for each flow, namely Benign or Bot.\n",
    "The dataset has been organized per day, for each day the raw data including the network traffic (Pcaps) and event logs (windows and Ubuntu event Logs) per machine\n",
    "are recorded.                  Download the dataset from the below wget command line provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://cse-cic-ids2018.s3.ca-central-1.amazonaws.com/Processed+Traffic+Data+for+ML+Algorithms/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.local/lib/python3.6/site-packages (1.0.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.6.1->pandas) (1.11.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: imblearn in ./.local/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in ./.local/lib/python3.6/site-packages (from imblearn) (0.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.local/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in ./.local/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (0.22.2.post1)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas --user\n",
    "! pip install imblearn --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart Notebook Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check number of available GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstZerodrp = ['Timestamp', 'BwdPSHFlags', 'FwdURGFlags', 'BwdURGFlags', 'CWEFlagCount', 'FwdBytsbAvg', 'FwdPktsbAvg',\n",
    "              'FwdBlkRateAvg', 'BwdBytsbAvg',\n",
    "              'BwdBlkRateAvg', 'BwdPktsbAvg']\n",
    "\n",
    "lstScaledrp = ['FwdPSHFlags', 'FINFlagCnt', 'SYNFlagCnt', 'RSTFlagCnt', 'PSHFlagCnt', 'ACKFlagCnt', 'URGFlagCnt',\n",
    "               'ECEFlagCnt']\n",
    "\n",
    "DATA_FILE = 'Network_Traffic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataFile():\n",
    "    \"\"\"\n",
    "    Reads data file and returns dataframe result\n",
    "    \"\"\"\n",
    "    chunksize = 100000\n",
    "    chunk_list = []\n",
    "    missing_values = [\"n/a\", \"na\", \"--\", \"Infinity\", \"infinity\", \"Nan\", \"NaN\"]\n",
    "\n",
    "    for chunk in pd.read_csv(DATA_FILE, chunksize=chunksize, na_values=missing_values):\n",
    "        chunk_list.append(chunk)\n",
    "#         break\n",
    "    dataFrme = pd.concat(chunk_list)\n",
    "\n",
    "    lstcols = []\n",
    "    for i in dataFrme.columns:\n",
    "        i = str(i).replace(' ', '').replace('/', '')\n",
    "        lstcols.append(i)\n",
    "    dataFrme.columns = lstcols\n",
    "    dfAllCpy = dataFrme.copy()\n",
    "    dataFrme = dataFrme.drop(lstZerodrp, axis=1)\n",
    "    return dataFrme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Traffic Input Dataset \n",
    "\n",
    "### Attribute Information\n",
    "    Features extracted from the captured traffic using CICFlowMeter-V3 = 69\n",
    "    After removal of noise/unwarranted features, number of feature columns chosen: 10\n",
    "    Features: FlowDuration,BwdPktLenMax,FlowIATStd,FwdPSHFlags,BwdPktLenMean,FlowIATMean,BwdIATMean,\n",
    "              FwdSegSizeMin,InitBwdWinByts,BwdPktLenMin\n",
    "    Flows labelled: Bot or Benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DstPort</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>FlowDuration</th>\n",
       "      <th>TotFwdPkts</th>\n",
       "      <th>TotBwdPkts</th>\n",
       "      <th>TotLenFwdPkts</th>\n",
       "      <th>TotLenBwdPkts</th>\n",
       "      <th>FwdPktLenMax</th>\n",
       "      <th>FwdPktLenMin</th>\n",
       "      <th>FwdPktLenMean</th>\n",
       "      <th>...</th>\n",
       "      <th>FwdSegSizeMin</th>\n",
       "      <th>ActiveMean</th>\n",
       "      <th>ActiveStd</th>\n",
       "      <th>ActiveMax</th>\n",
       "      <th>ActiveMin</th>\n",
       "      <th>IdleMean</th>\n",
       "      <th>IdleStd</th>\n",
       "      <th>IdleMax</th>\n",
       "      <th>IdleMin</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>141385</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>553</td>\n",
       "      <td>3773.0</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>61.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49684</td>\n",
       "      <td>6</td>\n",
       "      <td>281</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>279824</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>1086</td>\n",
       "      <td>10527.0</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>98.727273</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>274016</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>1285</td>\n",
       "      <td>6141.0</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "      <td>142.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DstPort  Protocol  FlowDuration  TotFwdPkts  TotBwdPkts  TotLenFwdPkts  \\\n",
       "0      443         6        141385           9           7            553   \n",
       "1    49684         6           281           2           1             38   \n",
       "2      443         6        279824          11          15           1086   \n",
       "3      443         6           132           2           0              0   \n",
       "4      443         6        274016           9          13           1285   \n",
       "\n",
       "   TotLenBwdPkts  FwdPktLenMax  FwdPktLenMin  FwdPktLenMean  ...  \\\n",
       "0         3773.0           202             0      61.444444  ...   \n",
       "1            0.0            38             0      19.000000  ...   \n",
       "2        10527.0           385             0      98.727273  ...   \n",
       "3            0.0             0             0       0.000000  ...   \n",
       "4         6141.0           517             0     142.777778  ...   \n",
       "\n",
       "   FwdSegSizeMin  ActiveMean  ActiveStd  ActiveMax  ActiveMin  IdleMean  \\\n",
       "0             20         0.0        0.0        0.0        0.0       0.0   \n",
       "1             20         0.0        0.0        0.0        0.0       0.0   \n",
       "2             20         0.0        0.0        0.0        0.0       0.0   \n",
       "3             20         0.0        0.0        0.0        0.0       0.0   \n",
       "4             20         0.0        0.0        0.0        0.0       0.0   \n",
       "\n",
       "   IdleStd  IdleMax  IdleMin   Label  \n",
       "0      0.0      0.0      0.0  Benign  \n",
       "1      0.0      0.0      0.0  Benign  \n",
       "2      0.0      0.0      0.0  Benign  \n",
       "3      0.0      0.0      0.0  Benign  \n",
       "4      0.0      0.0      0.0  Benign  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dataFile().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_na(dataFrme):\n",
    "    \"\"\"\n",
    "    Removing NA values\n",
    "    \"\"\"\n",
    "    na_lst = dataFrme.columns[dataFrme.isna().any()].tolist()\n",
    "    for j in na_lst:\n",
    "        dataFrme[j].fillna(0, inplace=True)\n",
    "    return dataFrme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_label(dataFrme):\n",
    "    \"\"\"\n",
    "    Create independent and Dependent Features\n",
    "    \"\"\"\n",
    "    columns = dataFrme.columns.tolist()\n",
    "    # Filter the columns to remove data we do not want \n",
    "    columns = [c for c in columns if c not in [\"Label\"]]\n",
    "    # Store the variable we are predicting \n",
    "    target = \"Label\"\n",
    "    # Define a random state \n",
    "    state = np.random.RandomState(42)\n",
    "    X = dataFrme[columns]\n",
    "    Y = dataFrme[target]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_substitution(dataFrme):\n",
    "    \"\"\"\n",
    "    Label substitution : 'Benign'as 0, 'Bot'as 1\n",
    "    \"\"\"\n",
    "    dictLabel = {'Benign': 0, 'Bot': 1}\n",
    "    dataFrme['Label'] = dataFrme['Label'].map(dictLabel)\n",
    "\n",
    "    LABELS = ['Benign', 'Bot']\n",
    "    count_classes = pd.value_counts(dataFrme['Label'], sort=True)\n",
    "    \n",
    "    # Get the Benign and the Bot values \n",
    "    Benign = dataFrme[dataFrme['Label'] == 0]\n",
    "    Bot = dataFrme[dataFrme['Label'] == 1]\n",
    "    return dataFrme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_class_imbalance(X,Y):\n",
    "    \"\"\"\n",
    "    Handle Class imbalancement \n",
    "    \"\"\"\n",
    "#    os_us = SMOTETomek(ratio=0.5)\n",
    "#    X_res, y_res = os_us.fit_sample(X, Y)\n",
    "    ros = RandomOverSampler(random_state=50)\n",
    "    X_res, y_res = ros.fit_sample(X, Y)\n",
    "    ibtrain_X = pd.DataFrame(X_res,columns=X.columns)\n",
    "    ibtrain_y = pd.DataFrame(y_res,columns=['Label']) \n",
    "    return ibtrain_X,ibtrain_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_features(ibtrain_X):\n",
    "    \"\"\"\n",
    "    Feature Selection - Correlation Ananlysis \n",
    "    \"\"\"\n",
    "    corr = ibtrain_X.corr()\n",
    "    cor_columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "    for i in range(corr.shape[0]):\n",
    "        for j in range(i + 1, corr.shape[0]):\n",
    "            if corr.iloc[i, j] >= 0.9:\n",
    "                if cor_columns[j]:\n",
    "                    cor_columns[j] = False\n",
    "\n",
    "    dfcorr_features = ibtrain_X[corr.columns[cor_columns]]\n",
    "    return dfcorr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_ten_features(dfcorr_features,ibtrain_X,ibtrain_y):\n",
    "    feat_X = dfcorr_features\n",
    "    feat_y = ibtrain_y['Label']\n",
    "    \n",
    "    #apply SelectKBest class to extract top 10 best features\n",
    "    bestfeatures = SelectKBest(score_func=f_classif, k=10)\n",
    "    fit = bestfeatures.fit(feat_X,feat_y)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(feat_X.columns)\n",
    "    #concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Features','Score']  #naming the dataframe columns\n",
    "    final_feature = featureScores.nlargest(10,'Score')['Features'].tolist()\n",
    "    final_feature.sort()\n",
    "    sort_fn = final_feature\n",
    "    dictLabel1 = {'Benign':0,'Bot':1}\n",
    "    ibtrain_y['Label']= ibtrain_y['Label'].map(dictLabel1)\n",
    "    selected_X = ibtrain_X[sort_fn]\n",
    "    selected_Y = ibtrain_y['Label']\n",
    "    return selected_X,selected_Y,sort_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(selected_X, selected_Y):\n",
    "    \"\"\"\n",
    "    Normalize data \n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    selected_X = pd.DataFrame(scaler.fit_transform(selected_X), columns=selected_X.columns, index=selected_X.index)\n",
    "    trainX, testX, trainY, testY = train_test_split(selected_X, selected_Y, test_size=0.25)\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(\"## Final features and Data pre-process for prediction\")\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(testX)\n",
    "    return trainX, testX, trainY, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "## Final features and Data pre-process for prediction\n",
      "-----------------------------------------------------------------\n",
      "         BwdPktLenMax  BwdPktLenMean  BwdPktLenMin  FlowDuration  \\\n",
      "1480863      0.076712       0.022095      0.000000  1.147000e-04   \n",
      "493104       0.000000       0.000000      0.000000  2.341667e-06   \n",
      "909012       1.000000       0.478892      0.000000  2.256308e-03   \n",
      "40256        0.803425       0.154737      0.000000  1.559668e-02   \n",
      "768475       0.000000       0.000000      0.000000  3.000000e-07   \n",
      "...               ...            ...           ...           ...   \n",
      "718967       0.036301       0.036311      0.037063  5.600000e-06   \n",
      "1364078      0.076712       0.022095      0.000000  8.210834e-05   \n",
      "503637       0.052740       0.052753      0.053846  1.103333e-05   \n",
      "380126       0.000000       0.000000      0.000000  7.083334e-07   \n",
      "1357498      0.000000       0.000000      0.000000  5.333333e-06   \n",
      "\n",
      "           FlowIATMax  FwdPktLenMin  FwdSegSizeMin  InitBwdWinByts  Protocol  \\\n",
      "1480863  1.070667e-04      0.000000       0.454545        0.003357  0.352941   \n",
      "493104   2.133333e-06      0.000000       0.454545        0.000000  0.352941   \n",
      "909012   6.069333e-04      0.000000       0.454545        0.003632  0.352941   \n",
      "40256    7.942875e-03      0.000000       0.454545        0.959061  0.352941   \n",
      "768475   1.833333e-07      0.000000       0.454545        0.000015  0.352941   \n",
      "...               ...           ...            ...             ...       ...   \n",
      "718967   5.600000e-06      0.025342       0.181818        0.000000  1.000000   \n",
      "1364078  7.581667e-05      0.000000       0.454545        0.003357  0.352941   \n",
      "503637   1.103333e-05      0.026027       0.181818        0.000000  1.000000   \n",
      "380126   7.083333e-07      0.000000       0.454545        0.000000  0.352941   \n",
      "1357498  5.333333e-06      0.000000       0.454545        0.000000  0.352941   \n",
      "\n",
      "         RSTFlagCnt  \n",
      "1480863         1.0  \n",
      "493104          0.0  \n",
      "909012          0.0  \n",
      "40256           1.0  \n",
      "768475          0.0  \n",
      "...             ...  \n",
      "718967          0.0  \n",
      "1364078         1.0  \n",
      "503637          0.0  \n",
      "380126          0.0  \n",
      "1357498         0.0  \n",
      "\n",
      "[381192 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "'''Reads data file and returns dataframe result'''\n",
    "dataFrme = read_dataFile()\n",
    "\n",
    "''' Removing NA values'''\n",
    "dataFrme = preprocess_na(dataFrme)\n",
    "\n",
    "'''Create independent and Dependent Features'''\n",
    "X, Y = create_features_label(dataFrme)\n",
    "\n",
    "'''Label substitution : 'Benign'as 0, 'Bot'as 1'''\n",
    "dataFrme = label_substitution(dataFrme)\n",
    "\n",
    "'''Handle Class imbalancement'''\n",
    "ibtrain_X, ibtrain_y = handle_class_imbalance(X, Y)\n",
    "\n",
    "'''Feature Selection - Correlation Ananlysis'''\n",
    "dfcorr_features = correlation_features(ibtrain_X)\n",
    "\n",
    "'''Feature Selection - SelectKBest : Return best 10 features'''\n",
    "selected_X, selected_Y, final_feature = top_ten_features(dfcorr_features, ibtrain_X, ibtrain_y)\n",
    "\n",
    "'''Normalize data '''\n",
    "trainX, testX, trainY, testY = normalize_data(selected_X, selected_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Serving Input Receiver Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_cols():\n",
    "  input_columns = [tf.feature_column.numeric_column(k,dtype=tf.dtypes.float64) for k in final_feature]\n",
    "  return input_columns\n",
    "feature_columns =  make_feature_cols()\n",
    "inputs = {}\n",
    "for feat in feature_columns:\n",
    "  inputs[feat.name] = tf.placeholder(shape=[None], dtype=feat.dtype)\n",
    "serving_input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Save Network Traffic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_DATA_DIR = os.getenv(\"TF_DATA_DIR\", \"/tmp/data/\")\n",
    "TF_MODEL_DIR = os.getenv(\"TF_MODEL_DIR\", \"network/\")\n",
    "TF_EXPORT_DIR = os.getenv(\"TF_EXPORT_DIR\", \"network/\")\n",
    "\n",
    "x1 = np.asarray(trainX[final_feature])\n",
    "y1 = np.asarray(trainY)\n",
    "\n",
    "x2 = np.asarray(testX[final_feature])\n",
    "y2 = np.asarray(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatFeatures(features):\n",
    "    formattedFeatures = {}\n",
    "    numColumns = features.shape[1]\n",
    "\n",
    "    for i in range(0, numColumns):\n",
    "        formattedFeatures[final_feature[i]] = features[:, i]\n",
    "\n",
    "    return formattedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:ParameterServerStrategy with compute_devices = ('/device:GPU:0', '/device:GPU:1'), variable_device = '/device:CPU:0'\n",
      "Number of devices: 2\n",
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'network/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.parameter_server_strategy.ParameterServerStrategyV1 object at 0x7fd6189a38d0>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd6189a3b70>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/model_fn.py:337: scalar (from tensorflow.python.framework.tensor_shape) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.TensorShape([]).\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Reduce to /device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "INFO:tensorflow:Saving checkpoints for 0 into network/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "INFO:tensorflow:loss = 177.77274, step = 0\n",
      "INFO:tensorflow:global_step/sec: 171.387\n",
      "INFO:tensorflow:loss = 54.15116, step = 100 (0.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.63\n",
      "INFO:tensorflow:loss = 57.91283, step = 200 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.08\n",
      "INFO:tensorflow:loss = 50.17385, step = 300 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.001\n",
      "INFO:tensorflow:loss = 51.102486, step = 400 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.105\n",
      "INFO:tensorflow:loss = 48.265537, step = 500 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.471\n",
      "INFO:tensorflow:loss = 54.264835, step = 600 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.302\n",
      "INFO:tensorflow:loss = 59.61172, step = 700 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.293\n",
      "INFO:tensorflow:loss = 50.98859, step = 800 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.127\n",
      "INFO:tensorflow:loss = 52.218384, step = 900 (0.464 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into network/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-21T10:20:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from network/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-21-10:20:15\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.910625, accuracy_baseline = 0.5, auc = 0.96381456, auc_precision_recall = 0.96775573, average_loss = 0.19750336, global_step = 1000, label/mean = 0.5, loss = 25.28043, precision = 0.84881866, prediction/mean = 0.49890405, recall = 0.99921876\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: network/model.ckpt-1000\n",
      "INFO:tensorflow:global_step/sec: 30.0604\n",
      "INFO:tensorflow:loss = 59.505424, step = 1000 (3.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.297\n",
      "INFO:tensorflow:loss = 67.35913, step = 1100 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.105\n",
      "INFO:tensorflow:loss = 66.86513, step = 1200 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.869\n",
      "INFO:tensorflow:loss = 56.32357, step = 1300 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.635\n",
      "INFO:tensorflow:loss = 45.94604, step = 1400 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.44\n",
      "INFO:tensorflow:loss = 44.21386, step = 1500 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.979\n",
      "INFO:tensorflow:loss = 56.190445, step = 1600 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.702\n",
      "INFO:tensorflow:loss = 48.492138, step = 1700 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.534\n",
      "INFO:tensorflow:loss = 43.992878, step = 1800 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.522\n",
      "INFO:tensorflow:loss = 61.32529, step = 1900 (0.449 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into network/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-21T10:20:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from network/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-21-10:20:22\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.91046876, accuracy_baseline = 0.5, auc = 0.96432376, auc_precision_recall = 0.96848965, average_loss = 0.19827217, global_step = 2000, label/mean = 0.5, loss = 25.378838, precision = 0.8485934, prediction/mean = 0.50081605, recall = 0.99921876\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: network/model.ckpt-2000\n",
      "INFO:tensorflow:global_step/sec: 33.874\n",
      "INFO:tensorflow:loss = 55.53856, step = 2000 (2.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.808\n",
      "INFO:tensorflow:loss = 43.283028, step = 2100 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.115\n",
      "INFO:tensorflow:loss = 53.347878, step = 2200 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.371\n",
      "INFO:tensorflow:loss = 50.321938, step = 2300 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.958\n",
      "INFO:tensorflow:loss = 45.54625, step = 2400 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.89\n",
      "INFO:tensorflow:loss = 59.614353, step = 2500 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.673\n",
      "INFO:tensorflow:loss = 75.54515, step = 2600 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.967\n",
      "INFO:tensorflow:loss = 58.271782, step = 2700 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.35\n",
      "INFO:tensorflow:loss = 61.307625, step = 2800 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.135\n",
      "INFO:tensorflow:loss = 51.2658, step = 2900 (0.459 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into network/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-21T10:20:28Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from network/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-21-10:20:30\n",
      "INFO:tensorflow:Saving dict for global step 3000: accuracy = 0.91117185, accuracy_baseline = 0.5, auc = 0.9671953, auc_precision_recall = 0.9708114, average_loss = 0.19664983, global_step = 3000, label/mean = 0.5, loss = 25.171179, precision = 0.84960806, prediction/mean = 0.50778615, recall = 0.99921876\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: network/model.ckpt-3000\n",
      "INFO:tensorflow:global_step/sec: 29.6597\n",
      "INFO:tensorflow:loss = 43.620857, step = 3000 (3.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.225\n",
      "INFO:tensorflow:loss = 58.414745, step = 3100 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.48\n",
      "INFO:tensorflow:loss = 49.177795, step = 3200 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.02\n",
      "INFO:tensorflow:loss = 42.757248, step = 3300 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.439\n",
      "INFO:tensorflow:loss = 55.71871, step = 3400 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.295\n",
      "INFO:tensorflow:loss = 56.0216, step = 3500 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.252\n",
      "INFO:tensorflow:loss = 44.88211, step = 3600 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.355\n",
      "INFO:tensorflow:loss = 47.98167, step = 3700 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.736\n",
      "INFO:tensorflow:loss = 44.250343, step = 3800 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.833\n",
      "INFO:tensorflow:loss = 59.417866, step = 3900 (0.477 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into network/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-21T10:20:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from network/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-21-10:20:37\n",
      "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.91132814, accuracy_baseline = 0.5, auc = 0.96436214, auc_precision_recall = 0.9685828, average_loss = 0.19773526, global_step = 4000, label/mean = 0.5, loss = 25.310114, precision = 0.8498339, prediction/mean = 0.51537627, recall = 0.99921876\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: network/model.ckpt-4000\n",
      "INFO:tensorflow:global_step/sec: 33.5318\n",
      "INFO:tensorflow:loss = 52.662148, step = 4000 (2.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.812\n",
      "INFO:tensorflow:loss = 53.222942, step = 4100 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.257\n",
      "INFO:tensorflow:loss = 51.303917, step = 4200 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.203\n",
      "INFO:tensorflow:loss = 39.88451, step = 4300 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.627\n",
      "INFO:tensorflow:loss = 55.30986, step = 4400 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.405\n",
      "INFO:tensorflow:loss = 45.827003, step = 4500 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.674\n",
      "INFO:tensorflow:loss = 52.3231, step = 4600 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.831\n",
      "INFO:tensorflow:loss = 45.671608, step = 4700 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.027\n",
      "INFO:tensorflow:loss = 51.38315, step = 4800 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.768\n",
      "INFO:tensorflow:loss = 48.050133, step = 4900 (0.429 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into network/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-21T10:20:42Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from network/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-21-10:20:44\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.9284375, accuracy_baseline = 0.5, auc = 0.9650054, auc_precision_recall = 0.9691113, average_loss = 0.17672765, global_step = 5000, label/mean = 0.5, loss = 22.62114, precision = 0.875308, prediction/mean = 0.49811894, recall = 0.99921876\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: network/model.ckpt-5000\n",
      "INFO:tensorflow:global_step/sec: 33.6\n",
      "INFO:tensorflow:loss = 45.73695, step = 5000 (2.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.471\n",
      "INFO:tensorflow:loss = 52.448254, step = 5100 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.65\n",
      "INFO:tensorflow:loss = 49.627975, step = 5200 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.659\n",
      "INFO:tensorflow:loss = 37.803143, step = 5300 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.648\n",
      "INFO:tensorflow:loss = 49.901627, step = 5400 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.993\n",
      "INFO:tensorflow:loss = 58.15101, step = 5500 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.318\n",
      "INFO:tensorflow:loss = 54.046345, step = 5600 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.213\n",
      "INFO:tensorflow:loss = 56.512283, step = 5700 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.146\n",
      "INFO:tensorflow:loss = 41.271103, step = 5800 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.607\n",
      "INFO:tensorflow:loss = 52.321632, step = 5900 (0.503 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into network/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-21T10:20:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from network/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-21-10:20:51\n",
      "INFO:tensorflow:Saving dict for global step 6000: accuracy = 0.92929685, accuracy_baseline = 0.5, auc = 0.96559227, auc_precision_recall = 0.9696617, average_loss = 0.17365463, global_step = 6000, label/mean = 0.5, loss = 22.227793, precision = 0.8766278, prediction/mean = 0.4932142, recall = 0.99921876\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: network/model.ckpt-6000\n",
      "INFO:tensorflow:global_step/sec: 28.5849\n",
      "INFO:tensorflow:loss = 47.239536, step = 6000 (3.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.577\n",
      "INFO:tensorflow:loss = 41.96554, step = 6100 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.538\n",
      "INFO:tensorflow:loss = 35.831642, step = 6200 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.171\n",
      "INFO:tensorflow:loss = 52.806458, step = 6300 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.406\n",
      "INFO:tensorflow:loss = 34.866756, step = 6400 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.868\n",
      "INFO:tensorflow:loss = 50.345528, step = 6500 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.235\n",
      "INFO:tensorflow:loss = 48.448982, step = 6600 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.511\n",
      "INFO:tensorflow:loss = 42.83622, step = 6700 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.214\n",
      "INFO:tensorflow:loss = 57.178307, step = 6800 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.674\n",
      "INFO:tensorflow:loss = 48.35739, step = 6900 (0.455 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into network/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-21T10:20:57Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from network/model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-21-10:20:59\n",
      "INFO:tensorflow:Saving dict for global step 7000: accuracy = 0.92875, accuracy_baseline = 0.5, auc = 0.96527594, auc_precision_recall = 0.969417, average_loss = 0.17439854, global_step = 7000, label/mean = 0.5, loss = 22.323013, precision = 0.87578744, prediction/mean = 0.48914015, recall = 0.99921876\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7000: network/model.ckpt-7000\n",
      "INFO:tensorflow:global_step/sec: 31.5027\n",
      "INFO:tensorflow:loss = 39.942295, step = 7000 (3.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.388\n",
      "INFO:tensorflow:loss = 43.844162, step = 7100 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.351\n",
      "INFO:tensorflow:loss = 46.35404, step = 7200 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.446\n",
      "INFO:tensorflow:loss = 52.167454, step = 7300 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.534\n",
      "INFO:tensorflow:loss = 45.596855, step = 7400 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.069\n",
      "INFO:tensorflow:loss = 37.2563, step = 7500 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.416\n",
      "INFO:tensorflow:loss = 47.542206, step = 7600 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.16\n",
      "INFO:tensorflow:loss = 35.857033, step = 7700 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.693\n",
      "INFO:tensorflow:loss = 54.959953, step = 7800 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.021\n",
      "INFO:tensorflow:loss = 41.597725, step = 7900 (0.467 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into network/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-21T10:21:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from network/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-21-10:21:06\n",
      "INFO:tensorflow:Saving dict for global step 8000: accuracy = 0.92929685, accuracy_baseline = 0.5, auc = 0.96634215, auc_precision_recall = 0.9702448, average_loss = 0.17296872, global_step = 8000, label/mean = 0.5, loss = 22.139996, precision = 0.8766278, prediction/mean = 0.49026367, recall = 0.99921876\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: network/model.ckpt-8000\n",
      "INFO:tensorflow:global_step/sec: 34.5842\n",
      "INFO:tensorflow:loss = 36.103703, step = 8000 (2.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.97\n",
      "INFO:tensorflow:loss = 45.949364, step = 8100 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.574\n",
      "INFO:tensorflow:loss = 51.02414, step = 8200 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.426\n",
      "INFO:tensorflow:loss = 47.472122, step = 8300 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.249\n",
      "INFO:tensorflow:loss = 33.85527, step = 8400 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.0372\n",
      "INFO:tensorflow:loss = 43.959183, step = 8500 (1.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.579\n",
      "INFO:tensorflow:loss = 37.25665, step = 8600 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.531\n",
      "INFO:tensorflow:loss = 47.622726, step = 8700 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.145\n",
      "INFO:tensorflow:loss = 47.04619, step = 8800 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.58\n",
      "INFO:tensorflow:loss = 54.711235, step = 8900 (0.412 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into network/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-21T10:21:12Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from network/model.ckpt-9000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-21-10:21:14\n",
      "INFO:tensorflow:Saving dict for global step 9000: accuracy = 0.9291406, accuracy_baseline = 0.5, auc = 0.96559954, auc_precision_recall = 0.96966827, average_loss = 0.17261793, global_step = 9000, label/mean = 0.5, loss = 22.095095, precision = 0.87638754, prediction/mean = 0.5019157, recall = 0.99921876\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9000: network/model.ckpt-9000\n",
      "INFO:tensorflow:global_step/sec: 33.8713\n",
      "INFO:tensorflow:loss = 49.012638, step = 9000 (2.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.315\n",
      "INFO:tensorflow:loss = 44.60961, step = 9100 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.519\n",
      "INFO:tensorflow:loss = 35.760094, step = 9200 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.521\n",
      "INFO:tensorflow:loss = 46.42647, step = 9300 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.925\n",
      "INFO:tensorflow:loss = 41.324787, step = 9400 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.203\n",
      "INFO:tensorflow:loss = 43.785683, step = 9500 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.621\n",
      "INFO:tensorflow:loss = 47.605244, step = 9600 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.217\n",
      "INFO:tensorflow:loss = 44.966274, step = 9700 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.683\n",
      "INFO:tensorflow:loss = 35.78029, step = 9800 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.546\n",
      "INFO:tensorflow:loss = 46.2996, step = 9900 (0.453 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into network/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-21T10:21:19Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from network/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-21-10:21:21\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.92890626, accuracy_baseline = 0.5, auc = 0.96552193, auc_precision_recall = 0.96960807, average_loss = 0.17399149, global_step = 10000, label/mean = 0.5, loss = 22.27091, precision = 0.8760274, prediction/mean = 0.489345, recall = 0.99921876\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: network/model.ckpt-10000\n",
      "INFO:tensorflow:Performing the final export in the end of training.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'BwdPktLenMax': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float64>, 'BwdPktLenMean': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float64>, 'BwdPktLenMin': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float64>, 'FlowDuration': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float64>, 'FlowIATMax': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float64>, 'FwdPktLenMin': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=float64>, 'FwdSegSizeMin': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=float64>, 'InitBwdWinByts': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=float64>, 'Protocol': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=float64>, 'RSTFlagCnt': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=float64>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'BwdPktLenMax': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float64>, 'BwdPktLenMean': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float64>, 'BwdPktLenMin': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float64>, 'FlowDuration': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float64>, 'FlowIATMax': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float64>, 'FwdPktLenMin': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=float64>, 'FwdSegSizeMin': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=float64>, 'InitBwdWinByts': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=float64>, 'Protocol': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=float64>, 'RSTFlagCnt': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=float64>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'BwdPktLenMax': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float64>, 'BwdPktLenMean': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float64>, 'BwdPktLenMin': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float64>, 'FlowDuration': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float64>, 'FlowIATMax': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float64>, 'FwdPktLenMin': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=float64>, 'FwdSegSizeMin': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=float64>, 'InitBwdWinByts': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=float64>, 'Protocol': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=float64>, 'RSTFlagCnt': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=float64>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from network/model.ckpt-10000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: network/export/network/temp-b'1587464481'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 52.783287.\n",
      "({'accuracy': 0.92890626, 'accuracy_baseline': 0.5, 'auc': 0.96552193, 'auc_precision_recall': 0.96960807, 'average_loss': 0.17399149, 'label/mean': 0.5, 'loss': 22.27091, 'precision': 0.8760274, 'prediction/mean': 0.489345, 'recall': 0.99921876, 'global_step': 10000}, [b'network/export/network/1587464481'])\n",
      "Training finished successfully\n"
     ]
    }
   ],
   "source": [
    "config = tf.estimator.RunConfig(model_dir=TF_MODEL_DIR, save_summary_steps=10, save_checkpoints_steps=10)\n",
    "\n",
    "# Provide list of GPUs should be used to train the model\n",
    "trainingFeatures = formatFeatures(x1)\n",
    "trainingCategories = y1\n",
    "\n",
    "testFeatures = formatFeatures(x2)\n",
    "testCategories = y2\n",
    "\n",
    "\n",
    "distribution = tf.distribute.experimental.ParameterServerStrategy()\n",
    "print('Number of devices: {}'.format(distribution.num_replicas_in_sync))\n",
    "\n",
    "# Configuration of  training model\n",
    "config = tf.estimator.RunConfig(train_distribute=distribution, model_dir=TF_MODEL_DIR, save_summary_steps=100, save_checkpoints_steps=1000)\n",
    "\n",
    "model = tf.estimator.DNNClassifier(hidden_units=[13,65,110],\n",
    "                                   feature_columns=feature_columns,\n",
    "                                   model_dir=TF_MODEL_DIR,\n",
    "                                   n_classes=2, config=config\n",
    "                                   )\n",
    "# Train Input Function\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((trainingFeatures, y1))\n",
    "    dataset = dataset.batch(128).repeat(10000)\n",
    "    return dataset\n",
    "\n",
    "# Test Input Function\n",
    "def eval_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((testFeatures, y2))\n",
    "    return dataset.batch(128).repeat(10000)\n",
    "\n",
    "export_final = tf.estimator.FinalExporter(TF_EXPORT_DIR, serving_input_receiver_fn=serving_input_receiver_fn)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn,\n",
    "                                    max_steps=10000)\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn,\n",
    "                                  steps=100,\n",
    "                                  exporters=export_final,\n",
    "                                  throttle_secs=1,\n",
    "                                  start_delay_secs=1)\n",
    "\n",
    "result = tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n",
    "print(result)\n",
    "\n",
    "print('Training finished successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update  storageUri in network_kfserving.yaml with pvc-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: \"serving.kubeflow.org/v1alpha2\"\r\n",
      "kind: \"InferenceService\"\r\n",
      "metadata:\r\n",
      "  name: \"network-model\"\r\n",
      "  namespace: anonymous\r\n",
      "spec:\r\n",
      "  default:\r\n",
      "    predictor:\r\n",
      "      tensorflow:\r\n",
      "        storageUri: \"pvc://workspace-gpu-test/network/export/network\"\r\n"
     ]
    }
   ],
   "source": [
    "pvcname = !(echo  $HOSTNAME | sed 's/.\\{2\\}$//')\n",
    "pvc = \"workspace-\"+pvcname[0]\n",
    "! sed -i \"s/nfs/$pvc/g\" network_kfserving.yaml\n",
    "! cat network_kfserving.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving Network Traffic Model using kubeflow kfserving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kubeflow.org/network-model created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f network_kfserving.yaml -n anonymous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME            URL                                                                  READY   DEFAULT TRAFFIC   CANARY TRAFFIC   AGE\r\n",
      "network-model   http://network-model.anonymous.example.com/v1/models/network-model   True    100                                55s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get inferenceservices -n anonymous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "Wait for inference service READY=\\\"True\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict data from serving after setting INGRESS_IP\n",
    "### Note - Use one of preprocessed row values from Data pre-process from prediction output cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying 10.30.118.172...\n",
      "* TCP_NODELAY set\n",
      "* Connected to 10.30.118.172 (10.30.118.172) port 31380 (#0)\n",
      "> POST /v1/models/network-model:predict HTTP/1.1\n",
      "> Host: network-model.anonymous.example.com\n",
      "> User-Agent: curl/7.58.0\n",
      "> Accept: */*\n",
      "> Content-Length: 301\n",
      "> Content-Type: application/x-www-form-urlencoded\n",
      "> \n",
      "* upload completely sent off: 301 out of 301 bytes\n",
      "< HTTP/1.1 200 OK\n",
      "< content-length: 293\n",
      "< content-type: application/json\n",
      "< date: Tue, 21 Apr 2020 10:23:02 GMT\n",
      "< x-envoy-upstream-service-time: 50\n",
      "< server: istio-envoy\n",
      "< \n",
      "{\n",
      "    \"predictions\": [\n",
      "        {\n",
      "            \"class_ids\": [0],\n",
      "            \"classes\": [\"0\"],\n",
      "            \"all_class_ids\": [0, 1],\n",
      "            \"all_classes\": [\"0\", \"1\"],\n",
      "            \"logistic\": [0.0],\n",
      "            \"probabilities\": [1.0, 0.0],\n",
      "            \"logits\": [-341.46994]\n",
      "        }\n",
      "    ]\n",
      "* Connection #0 to host 10.30.118.172 left intact\n",
      "}"
     ]
    }
   ],
   "source": [
    "! curl -v -H \"Host: network-model.anonymous.example.com\" http://<<INGRESS_IP>>:<<PORT>>/v1/models/network-model:predict -d '{\"signature_name\":\"predict\",\"instances\":[{\"BwdPktLenMax\":[0.158904] , \"BwdPktLenMean\":[0.039736] , \"BwdPktLenMin\":[0.00000], \"FlowDuration\":[0.053778] , \"FlowIATMax\":[0.053262] , \"FwdPktLenMin\":[0.0] , \"FwdSegSizeMin\":[0.454545] , \"InitBwdWinByts\":[1.0] , \"Protocol\":[0.0] , \"RSTFlagCnt\":[0.003357]}]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete kfserving model & Clean up of stored models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kubeflow.org \"network-model\" deleted\n",
      "apiVersion: \"serving.kubeflow.org/v1alpha2\"\n",
      "kind: \"InferenceService\"\n",
      "metadata:\n",
      "  name: \"network-model\"\n",
      "  namespace: anonymous\n",
      "spec:\n",
      "  default:\n",
      "    predictor:\n",
      "      tensorflow:\n",
      "        storageUri: \"pvc://nfs/network/export/network\"\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f network_kfserving.yaml\n",
    "!rm -rf /mnt/network\n",
    "pvcname = !(echo  $HOSTNAME | sed 's/.\\{2\\}$//')\n",
    "pvc = \"workspace-\"+pvcname[0]\n",
    "! sed -i \"s/$pvc/nfs/g\" network_kfserving.yaml\n",
    "! cat network_kfserving.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
